{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from hmmlearn import hmm\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open txt and deleting empty rows\n",
    "with open(\"../sample/HP.txt\", \"r\", encoding = \"latin-1\") as f:\n",
    "   HP_text = f.read()\n",
    "type(HP_text)\n",
    "#HP_text = HP_text.replace(\"\\n\", \"\")\n",
    "print(HP_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a lemmatizer that turns all charachters lower-case, splits it into words and removes all punctuation\n",
    "# except for end of sentence punctations. \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(message):\n",
    "    message = message.lower().replace('.', ' .').replace('!', ' !').replace('?', ' ?')\n",
    "    #''.join([char for char in message.lower()\n",
    "                       #if char.isalnum() or char.isspace()])\n",
    "    words= [lemmatizer.lemmatize(word, pos='v') \n",
    "            for word in message.split()]\n",
    "    punctuations = '\"#$%&\\'()*+,-/:;<=>@[\\\\]^_`{|}~'\n",
    "    table = str.maketrans('', '', punctuations)\n",
    "    return [w.translate(table) for w in words]\n",
    "\n",
    "lemmatize(HP_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_words = lemmatize(HP_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentencer(text):\n",
    "    '''split by . ? !\n",
    "    filter empty'''\n",
    "    sentences = re.split(r'[.?!]', text)\n",
    "    return [sentence for sentence in sentences if len(sentence)]\n",
    "    \n",
    "def preprocess(text):\n",
    "    sentences = sentencer(text)\n",
    "    return [lemmatize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_lemmas = preprocess(HP_text)\n",
    "HP_words = [word for sentence in HP_lemmas for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = set(HP_words)\n",
    "le = LabelEncoder()\n",
    "le.fit(list(alphabet))\n",
    "\n",
    "seq = le.transform(HP_words)\n",
    "features = np.fromiter(seq, np.int64)\n",
    "features = np.atleast_2d(features).T\n",
    "fd = FreqDist(seq)\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=8, init_params='ste')\n",
    "\n",
    "lengths = [len(lemma) for lemma in HP_lemmas]\n",
    "model = model.fit(features, lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequencies():\n",
    "    frequencies = np.fromiter((fd.freq(i) for i in range(len(alphabet))), dtype=np.float64)\n",
    "    emission_prob = np.stack([frequencies] * 8)\n",
    "\n",
    "    model = hmm.MultinomialHMM(n_components=8, init_params='st')\n",
    "    model.emissionprob_ = emission_prob\n",
    "    return model\n",
    "model = frequencies().fit(features, lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols, _states = model.sample(8)\n",
    "\n",
    "output = le.inverse_transform(np.squeeze(symbols))\n",
    "\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
